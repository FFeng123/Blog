动手学深度学习这本书，是我上高二的时候买的。



当时是想通过这本书，把深度学习、Python、线性代数全都搞懂，后来因为一些原因（似乎是因为电脑不支持CUDA，又不想用在线的计算）暂停了，然后这本书一直放在教室当吉祥物，直到高中毕业带回家，到现在开始继续学习···



现在，向量怎么乘都忘了，为了能尽快学习，数学什么的东西就不管了，公式什么的都不看了，留到大学再说，反正有神经网络框架，会用就行。



这本书上用的是MXNet，但是看好多项目都是PyTorch写的，尽管框架都是相通的，但是还是主流一些好，于是[《动手学深度学习》(PyTorch版)](https://tangshusen.me/Dive-into-DL-PyTorch/)安排。



HelloWorld很简单（线性回归），随随便便写完跑起来，图像分类也好写，毕竟就是把框架给的东西拼拼凑凑呗，但是到循环神经网络难到了我。



## 出现问题

感觉正常人看书直接就明白了，但是我看不懂公式。



循环神经网络怎么跑的，高中的时候就明白了，时间维度也完全明白，但一看代码就懵了。



向RNN传递的向量和RNN计算返回的向量书上写的都很清楚，我却完全理解不了向量每个维度是什么意思、循环网络内部的参数是怎么传递的······



让我对着书上的代码复现一遍都难。



## 解决问题



搜索引擎没能解决我的问题，因为搜出来的都是数学公式。



忽然想到B站，于是搜了一下，找到了一个有用的视频，虽然依然都是公式、虽然一句话里插好几个英语单词（就不能好好讲中文？），但举了很多向量维度和维度作用的例子。



在一般的神经网络中，输入训练模型的向量维度是这样的：（批次，特征数），如果第一层是全连接层那么就只是这样，如果是二维卷积层，那么特征是有维度的，像这样（通道数，宽度，高度），输入模型的向量维度就像这样（批次，通道数，宽度，高度）。



但这只针对于能用一个数值表示的数据，像价格、像素点颜色。像文字，往往按词或字表示成一个N维向量，所以上面的向量维度就变成（批次，特征数，N）和（批次，通道数，宽度，高度，N）。



循环神经网络下一时刻的输入（包括喂进去的数据和上一层传过来的记忆）必须等上一时刻计算完成才能完全知道，所以循环神经网络训练的时候，训练多少个时刻就要喂多少次数据。为了方便将传入的向量拆分成不同时刻的输入（这个原因是猜测的），给PyTorch RNN的向量的第一维度是时间，像这样：（时间长度（单词数量），批次，单词的向量长度）。



然后PyTorch RNN会返回两个向量，一个是所有时刻的最终输出（第一维度是时间），一个是最终时刻的所有记忆，（各层都会向后传递记忆）单层就只有一维，多层就有多维，传到最后时刻就把记忆返回。



----



现在学习神经网络的方法和我学习编程的方法相似，底层基础什么的全都不要，先要能真正写出来东西。












