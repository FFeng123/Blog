

GitHub上发现了[ChatGLM2-6B](https://github.com/THUDM/ChatGLM2-6B)这个项目，本来心想这种项目见得多了，肯定是我电脑跑不动的，点进去忽然见看到了6G显存什么什么的，我跑的得动！



闲的也是闲的，好久没碰Golang了，整活吧！



## 试探

首先试探下这个项目是不是真的能在我电脑上跑。



GPU版本的Pytorch之前已经折腾着安装好了，理论上环境不是什么问题，缺啥补啥了。



安装好需要的库之后，直接运行`webdemo.py`，失败了，原因嘛，光clone了项目，模型没有啊，没有模型程序自动下载，但是服务器在国内不怎么稳定。



ChatGLM2-6B训练好的模型似乎有两个版本，一个是正常的，模型有13G，占运存大，还有一个量化过的，模型4G。



看看我8G的4060，当然要4G模型，在[清华大学云盘](https://cloud.tsinghua.edu.cn/d/674208019e314311ab5c/?p=%2F&mode=list)下载好了模型，接下来是加载模型。



弄了很久，Readme写的也不是很清楚，看了好多报错，最终找到了方法。



项目克隆下来，里面有`api.py` `webdemo.py` 什么的可以直接拿来用的启动脚本，里面有个 `THUDM/chatglm2-6b` 表示加载模型的路径，我直接把这个路径改成`THUDM`然后项目内新建文件夹`THUDM`。



ReadMe里面给了[Hugging Face](https://huggingface.co/THUDM/chatglm2-6b)，这个`THUDM`文件夹里面需要放这个仓库里面的文件，但是，量化过的模型不能直接用这个，直接点进去这个仓库也能发现，这个仓库里面放着13G的模型，找来找去，发现还有其他仓库，[这个](https://huggingface.co/THUDM/chatglm2-6b-int4/tree/main)就是了。



文件直接扔进去，`webdemo.py`直接启动，`import`失败缺啥装啥，成功！而且生成速度很可以。



好了，确定项目能用。



## 企鹅



项目提供了`api.py`，省的自己写了，这是个http服务器，提供AI推理接口。



我想把它接入到企鹅聊天群上。



用[go-cqhttp](https://github.com/Mrs4s/go-cqhttp)对接企鹅就好了。我的小号似乎被风控了，目前只能用Android手表登录+手机扫码登录。



但是cqhttp提供了风控账号登录的方法，似乎是扒拉手机企鹅apk的某个代码文件，然后用解释器执行，对发往服务器的数据包进行处理，使服务器端无法分辨是不是真正的客户端登录。



我只需要下载项目、设置一下签名服务器地址就好了。



然而我并不会弄，这个签名服务器总是报错，也懒得再研究了，凑合凑合能用就行了。



## 写程序



过滤cq-http给的消息，并进行处理，发给API推理，推理完再回应cq-http，就写一个这样的程序就好了。



AI记忆的问题需要我的程序处理，经实际测试，发给API和API发回的历史纪录数组的类型是这样的：`[][2]string`，既数组里面的每个元素存了两个字符串，前一个是用户说的，后一个是AI说的。API的最大长度参数限制的是历史记录+这次用户说的+这次AI将要说的。



Unicode YYDS，调用API没乱码。



还有一个重要的事情，调教，聊天AI嘛，都要调教一下的，虽然不调教ChatGLM2-6B没什么限制，但是说话更可爱一些当然更好啦。



只需要从一开始加一个对话历史，[“请你·····”."好的我知道了"]，然后加一些逻辑保护这个历史不要被删掉···



最终，写了一个不怎么完美，但是能用的聊天机器人。[项目地址](https://github.com/FFeng123/ChatBot-QQ)



最初我想加一些功能，比如说，删除记忆，当有人给AI说让他删除记忆的时候他在回复中加上一些特殊文本，像是`[clean]`，当程序发现这种文本的时候就会执行特定的代码。



但是奈何调教不出来，没办法。



虽不完美但还是很成功的。
